{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long Short Term Memory (LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem with standard recurrent nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard recurrent nets, during training, will have gradients that either vanish or explode, depending on the size of the largest eigenvalue of the weight matrix. Illustration of a vanishing gradient: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"vanishing_gradient_50.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTMs and some other types of *gated* recurrent nets (GRUs among others) don't suffer from this problem. Here is how gradient would propagate through time with an LSTM:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"lstm_gradient_50.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure of LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single LSTM unit looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"lstm_diagram_50.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One could have multiple LSTM units layed out in parallel, or LSTM units on top of LSTM units, or even bidirectional LSTMs. Here is an example of a parallel layout:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"lstm_multiple_units_50.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theano Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After http://christianherta.de/lehre/dataScience/machineLearning/neuralNetworks/LSTM.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "dtype=theano.config.floatX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"LSTM_definition_corrected_50.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# squashing of the gates should result in values between 0 and 1\n",
    "# therefore we use the logistic function\n",
    "sigma = lambda x: 1 / (1 + T.exp(-x))\n",
    "\n",
    "# for the other activation function we use the tanh\n",
    "act = T.tanh\n",
    "\n",
    "# sequences: x_t\n",
    "# prior results: h_tm1, c_tm1\n",
    "# non-sequences: W_xi, W_hi, W_ci, b_i, W_xf, W_hf, W_cf, b_f, W_xc, W_hc, b_c, \n",
    "#                W_xy, W_hy, W_cy, b_y\n",
    "def one_lstm_step(x_t, h_tm1, c_tm1, W_xi, W_hi, W_ci, b_i, W_xf, W_hf, W_cf, \n",
    "                  b_f, W_xc, W_hc, b_c, W_xy, W_ho, W_cy, b_o, W_hy, b_y):\n",
    "    i_t = sigma(theano.dot(x_t, W_xi) + theano.dot(h_tm1, W_hi) + \\\n",
    "                theano.dot(c_tm1, W_ci) + b_i)\n",
    "    f_t = sigma(theano.dot(x_t, W_xf) + theano.dot(h_tm1, W_hf) + \\\n",
    "                theano.dot(c_tm1, W_cf) + b_f)\n",
    "    c_t = f_t * c_tm1 + i_t * act(theano.dot(x_t, W_xc) + \n",
    "                                  theano.dot(h_tm1, W_hc) + b_c) \n",
    "    o_t = sigma(theano.dot(x_t, W_xo)+ theano.dot(h_tm1, W_ho) + \n",
    "                theano.dot(c_t, W_co)  + b_o)\n",
    "    h_t = o_t * act(c_t)\n",
    "    y_t = sigma(theano.dot(h_t, W_hy) + b_y) \n",
    "    return [h_t, c_t, y_t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_weights(sizeX, sizeY):\n",
    "    values = np.ndarray([sizeX, sizeY], dtype=dtype)\n",
    "    for dx in xrange(sizeX):\n",
    "        values[dx,:] = np.random.uniform(low=-1., high=1., size=(sizeY,))\n",
    "    _, svs, _ = np.linalg.svd(values)\n",
    "    #svs[0] is the largest singular value                      \n",
    "    values = values / svs[0]\n",
    "    return values  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"lstm_pooling.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_in = 7 # for embedded reber grammar\n",
    "n_hidden = n_i = n_c = n_o = n_f = 10\n",
    "n_y = 7 # for embedded reber grammar\n",
    "\n",
    "# initialize weights\n",
    "# i_t and o_t should be \"open\" or \"closed\"\n",
    "# f_t should be \"open\" (don't forget at the beginning of training)\n",
    "# we try to archive this by appropriate initialization of the corresponding biases \n",
    "\n",
    "W_xi = theano.shared(sample_weights(n_in, n_i))  \n",
    "W_hi = theano.shared(sample_weights(n_hidden, n_i))  \n",
    "W_ci = theano.shared(sample_weights(n_c, n_i))  \n",
    "b_i = theano.shared(np.cast[dtype](np.random.uniform(-0.5,.5,size = n_i)))\n",
    "W_xf = theano.shared(sample_weights(n_in, n_f)) \n",
    "W_hf = theano.shared(sample_weights(n_hidden, n_f))\n",
    "W_cf = theano.shared(sample_weights(n_c, n_f))\n",
    "b_f = theano.shared(np.cast[dtype](np.random.uniform(0, 1.,size = n_f)))\n",
    "W_xc = theano.shared(sample_weights(n_in, n_c))  \n",
    "W_hc = theano.shared(sample_weights(n_hidden, n_c))\n",
    "b_c = theano.shared(np.zeros(n_c, dtype=dtype))\n",
    "W_xo = theano.shared(sample_weights(n_in, n_o))\n",
    "W_ho = theano.shared(sample_weights(n_hidden, n_o))\n",
    "W_co = theano.shared(sample_weights(n_c, n_o))\n",
    "b_o = theano.shared(np.cast[dtype](np.random.uniform(-0.5,.5,size = n_o)))\n",
    "W_hy = theano.shared(sample_weights(n_hidden, n_y))\n",
    "b_y = theano.shared(np.zeros(n_y, dtype=dtype))\n",
    "\n",
    "c0 = theano.shared(np.zeros(n_hidden, dtype=dtype))\n",
    "h0 = T.tanh(c0)\n",
    "\n",
    "params = [W_xi, W_hi, W_ci, b_i, W_xf, W_hf, W_cf, b_f, W_xc, W_hc, b_c,\n",
    "          W_xo, W_ho, W_co, b_o, W_hy, b_y, c0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#first dimension is time\n",
    "\n",
    "#input \n",
    "v = T.matrix(dtype=dtype)\n",
    "\n",
    "# target\n",
    "target = T.matrix(dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hidden and outputs of the entire sequence\n",
    "[h_vals, _, y_vals], _ = theano.scan(\n",
    "    fn=one_lstm_step, \n",
    "    sequences = dict(input=v, taps=[0]), \n",
    "    outputs_info = [h0, c0, None ], # corresponds to return type of fn\n",
    "    non_sequences = [W_xi, W_hi, W_ci, b_i, W_xf, W_hf, W_cf, b_f, W_xc, W_hc,\n",
    "                     b_c, W_xo, W_ho, W_co, b_o, W_hy, b_y]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cross-entropy cost\n",
    "cost = -T.mean(target * T.log(y_vals) + (1.- target) * T.log(1. - y_vals))\n",
    "learning_rate = theano.shared(np.cast[dtype](.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gparams = []\n",
    "for param in params:\n",
    "    gparam = T.grad(cost, param)\n",
    "    gparams.append(gparam)\n",
    "\n",
    "updates=[]\n",
    "for param, gparam in zip(params, gparams):\n",
    "    updates.append((param, param - gparam * learning_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Reber Grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple version of Reber grammar:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"reberGrammar.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedded version:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"embeddedReberGrammar.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import reberGrammar\n",
    "train_data = reberGrammar.get_n_embedded_examples(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learn_rnn_fn = theano.function(inputs=[v, target],\n",
    "                               outputs=cost,\n",
    "                               updates=updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_epochs=200\n",
    "train_errors = np.ndarray(nb_epochs)\n",
    "\n",
    "def train_rnn(train_data):      \n",
    "    for epoch in range(nb_epochs):\n",
    "        error = 0.0\n",
    "        for j in range(len(train_data)):  \n",
    "            index = np.random.randint(0, len(train_data))\n",
    "            i, o = train_data[index]\n",
    "            train_cost = learn_rnn_fn(i, o)\n",
    "            error += train_cost\n",
    "        train_errors[epoch] = error \n",
    "        print epoch, error\n",
    "\n",
    "train_rnn(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 50)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEPCAYAAABCyrPIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2aadf8fc7590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.arange(nb_epochs), train_errors, 'b-')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('error')\n",
    "plt.ylim(0., 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  0.  0.  0.  0.  0.]\n",
      "[  1.49718358e-03   5.11488557e-01   2.24089254e-05   2.31526319e-05\n",
      "   4.82351184e-01   1.14407670e-03   4.51986343e-02]\n",
      "\n",
      "[ 0.  0.  0.  0.  1.  0.  0.]\n",
      "[  1.49719242e-03   4.76992846e-01   2.67206706e-05   2.75313341e-05\n",
      "   4.68519747e-01   9.89855267e-04   4.08085883e-02]\n",
      "\n",
      "[ 0.  1.  0.  0.  0.  0.  0.]\n",
      "[  1.79453695e-03   5.27297914e-01   2.28836398e-05   2.36722208e-05\n",
      "   5.08574784e-01   1.02745695e-03   4.42106985e-02]\n",
      "\n",
      "[ 0.  1.  0.  0.  0.  0.  0.]\n",
      "[  2.36487761e-03   5.48388064e-01   2.36356482e-05   2.45287374e-05\n",
      "   5.39140880e-01   8.58101412e-04   4.38702144e-02]\n",
      "\n",
      "[ 0.  0.  0.  0.  1.  0.  0.]\n",
      "[  1.54337706e-03   4.81554449e-01   2.67334453e-05   2.75382135e-05\n",
      "   4.72645819e-01   9.75941017e-04   4.06297147e-02]\n",
      "\n",
      "[ 0.  0.  0.  0.  1.  0.  0.]\n",
      "[  1.57485087e-03   4.65496391e-01   2.74381327e-05   2.82618166e-05\n",
      "   4.68997151e-01   9.57042444e-04   4.19592336e-02]\n",
      "\n",
      "[ 0.  0.  0.  0.  1.  0.  0.]\n",
      "[  1.52073987e-03   4.54384089e-01   2.78926527e-05   2.87623407e-05\n",
      "   4.63348716e-01   9.81677091e-04   4.19134200e-02]\n",
      "\n",
      "[ 0.  1.  0.  0.  0.  0.  0.]\n",
      "[  1.50685362e-03   5.11413157e-01   2.24675550e-05   2.32144685e-05\n",
      "   4.82462585e-01   1.14849152e-03   4.53043953e-02]\n",
      "\n",
      "[ 0.  0.  0.  0.  1.  0.  0.]\n",
      "[  1.50809926e-03   4.79996234e-01   2.66148345e-05   2.74223021e-05\n",
      "   4.70798373e-01   9.84125421e-04   4.06710915e-02]\n",
      "\n",
      "[ 0.  0.  0.  0.  1.  0.  0.]\n",
      "[  1.48749596e-03   4.79821503e-01   2.66087281e-05   2.74339600e-05\n",
      "   4.68479663e-01   9.85668157e-04   4.06760164e-02]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = theano.function(inputs = [v], outputs = y_vals)\n",
    "test_data = reberGrammar.get_n_embedded_examples(10)\n",
    "\n",
    "def print_out(test_data):\n",
    "    for i, o in test_data:\n",
    "        p = predictions(i)\n",
    "        print o[-2] # target\n",
    "        print p[-2] # prediction\n",
    "        print \n",
    "print_out(test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python2",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
